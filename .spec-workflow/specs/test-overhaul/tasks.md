# test-overhaul - Tasks

## Overview
Comprehensive overhaul of test infrastructure: fix failing tests, improve test productivity, achieve 95%+ pass rate, 80%+ coverage, and establish sustainable test balance across unit/integration/E2E layers.

## Current State Analysis
| Metric | Current | Target |
|--------|---------|--------|
| Backend Tests | 962/962 (100%) | Maintain |
| Frontend Tests | 1,163/1,249 (75.9%) | ≥95% (1,187+) |
| Accessibility | 23/23 (100%) | Maintain |
| Coverage | Blocked | ≥80% |
| Unit Test Speed | 5s timeout | ≤3s |
| CI Total Time | ~45min | ≤30min |

## Critical Blocker
**WebSocket Mock Infrastructure** - jest-websocket-mock has JSON deserialization issues causing 72 test failures.

---

## Task 1: Fix WebSocket Mock Infrastructure (CRITICAL)

- [x] 1.1 Diagnose and fix jest-websocket-mock deserialization
  - File: `keyrx_ui/src/test/mocks/websocketHandlers.ts`, `tests/helpers/websocket.ts`
  - Error: `SyntaxError: Unexpected token 'e', "test message" is not valid JSON`
  - Fix JSON message serialization in mock handlers
  - Ensure all WebSocket messages are valid JSON
  - Add message validation before sending
  - Purpose: Unblock 72 test failures
  - _Leverage: keyrx_ui/src/test/mocks/websocketHandlers.ts, jest-websocket-mock docs_
  - _Requirements: WebSocket tests pass without JSON errors_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Test Infrastructure Engineer | Task: Fix WebSocket mock deserialization. Debug jest-websocket-mock usage in websocketHandlers.ts. Ensure all messages sent via mock.send() are JSON.stringify'd. Add validation layer to catch non-JSON messages. | Restrictions: Don't replace mock library yet, fix usage first | Success: All WebSocket-related tests pass, no JSON parse errors | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [x] 1.2 Create standardized WebSocket test utilities
  - File: `keyrx_ui/tests/helpers/websocket.ts` (enhance)
  - Create `setupMockWebSocket()` with auto-cleanup
  - Create `sendRpcResponse(id, result)` helper
  - Create `sendRpcError(id, code, message)` helper
  - Auto-close WebSocket connections in afterEach
  - Purpose: Consistent WebSocket testing patterns
  - _Leverage: keyrx_ui/tests/helpers/websocket.ts existing code_
  - _Requirements: Standardized WebSocket test helpers_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Test Utilities Developer | Task: Enhance websocket.ts: Add setupMockWebSocket() returning {server, cleanup}. Add sendRpcResponse(server, id, result) and sendRpcError(). Auto-cleanup in afterEach. Add TypeScript types for RPC messages. | Restrictions: Must work with existing test patterns, maintain backward compat | Success: New helper functions exported, cleanup automatic | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 1.3 Migrate failing tests to new WebSocket helpers
  - Files: `keyrx_ui/src/pages/*.test.tsx`, `keyrx_ui/src/api/websocket.test.ts`
  - Update ConfigPage.test.tsx (5 failures)
  - Update ProfilesPage.test.tsx (1 failure)
  - Update websocket.test.ts (1 error)
  - Use new standardized helpers
  - Purpose: Fix remaining WebSocket test failures
  - _Leverage: tests/helpers/websocket.ts new utilities_
  - _Requirements: All WebSocket-dependent tests pass_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Test Migration Engineer | Task: Migrate failing tests: 1) ConfigPage.test.tsx - use setupMockWebSocket(), 2) ProfilesPage.test.tsx - fix Edit button async timing, 3) websocket.test.ts - use typed RPC helpers. Ensure cleanup. | Restrictions: Keep test assertions, only change setup/mocking | Success: All 7 failing tests now pass | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

---

## Task 2: Fix Async/Timing Test Issues

- [ ] 2.1 Fix ProfilesPage Edit button rendering issue
  - File: `keyrx_ui/src/pages/ProfilesPage.test.tsx`
  - Issue: Edit button not found at line 383
  - Root cause: Async state update timing
  - Solution: Use findByRole with waitFor, not getByRole
  - Add data-testid for reliable selection
  - Purpose: Fix component rendering race condition
  - _Leverage: keyrx_ui/src/pages/ProfilesPage.test.tsx, @testing-library/react_
  - _Requirements: Edit button test passes reliably_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: React Testing Specialist | Task: Fix ProfilesPage test at line 383. Change getByRole to findByRole for Edit button. Add explicit waitFor on profile card render. Add data-testid="edit-profile-{name}" to Edit button component. | Restrictions: Don't add arbitrary delays, use proper async utilities | Success: Test passes consistently on 10 consecutive runs | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 2.2 Fix RhaiSyncEngine unhandled errors
  - File: `keyrx_ui/src/components/RhaiSyncEngine.tsx`, related tests
  - Issue: Uncaught exceptions in timeout callbacks after test completion
  - Solution: Clear timeouts in cleanup, add error boundaries
  - Add proper abort handling for async operations
  - Purpose: Fix 2 unhandled errors in ConfigPage tests
  - _Leverage: keyrx_ui/src/components/RhaiSyncEngine.tsx:199_
  - _Requirements: No unhandled errors in test output_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: React Async Error Handler | Task: Fix RhaiSyncEngine: 1) Store timeout IDs in ref, 2) Clear all timeouts in useEffect cleanup, 3) Add AbortController for async ops, 4) Check mounted state before state updates. Update tests to wait for cleanup. | Restrictions: Don't suppress errors, fix root cause | Success: ConfigPage tests complete without unhandled errors | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

---

## Task 3: Improve Test Productivity

- [ ] 3.1 Reduce unit test timeout and add slow test warnings
  - File: `keyrx_ui/vitest.unit.config.ts`
  - Reduce timeout from 5000ms to 3000ms
  - Add slowTestThreshold: 1000ms (warn if test > 1s)
  - Add reporter for slow tests
  - Purpose: Catch slow tests early, faster feedback
  - _Leverage: keyrx_ui/vitest.unit.config.ts_
  - _Requirements: Tests fail fast, slow tests flagged_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Test Config Specialist | Task: Update vitest.unit.config.ts: Set testTimeout: 3000, hookTimeout: 2000, Add slowTestThreshold: 1000. Add custom reporter to log slow tests. Verify all tests still pass with new limits. | Restrictions: Don't break existing tests, adjust limits if needed | Success: Unit tests complete faster, slow tests visible | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 3.2 Add parallel test execution optimization
  - File: `keyrx_ui/vitest.unit.config.ts`, `vitest.integration.config.ts`
  - Configure optimal thread pool size
  - Isolate tests that can't run in parallel
  - Add `--shard` support for CI splitting
  - Purpose: Faster test execution on multi-core machines
  - _Leverage: Vitest parallel configuration_
  - _Requirements: Tests run in parallel where possible_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: CI Performance Engineer | Task: Optimize parallel execution: Set pool: 'threads', poolOptions.threads.maxThreads based on CPU. Mark tests needing isolation with describe.sequential. Add npm script for sharded CI runs. | Restrictions: Don't break test isolation, verify no race conditions | Success: Test suite runs 30%+ faster | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 3.3 Create focused test run scripts
  - File: `keyrx_ui/package.json`
  - `test:changed` - Only test changed files (git diff)
  - `test:related` - Test files related to changes
  - `test:failed` - Re-run only failed tests
  - `test:watch:smart` - Watch mode with smart filtering
  - Purpose: Developer productivity for fast iteration
  - _Leverage: Vitest --changed, --related flags_
  - _Requirements: Quick test commands for development_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: DX Engineer | Task: Add npm scripts: "test:changed": "vitest --changed", "test:related": "vitest --related", "test:failed": "vitest --rerun", "test:watch:smart": "vitest --watch --changed". Document in README. | Restrictions: Keep existing test scripts, add new ones | Success: Developers can run focused tests quickly | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

---

## Task 4: Establish Test Balance Strategy

- [ ] 4.1 Document test pyramid strategy
  - File: `keyrx_ui/tests/README.md` (create)
  - Define test pyramid: Unit (70%) > Integration (20%) > E2E (10%)
  - Define when to use each test type
  - Define test naming conventions
  - Define test file organization
  - Purpose: Consistent test strategy across team
  - _Leverage: Existing test structure analysis_
  - _Requirements: Clear test guidelines documented_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Test Strategy Architect | Task: Create tests/README.md with: Test pyramid ratios, when to use unit/integration/E2E, naming conventions (*.test.tsx, *.integration.test.tsx, *.e2e.ts), file organization, coverage expectations per layer. | Restrictions: Align with existing patterns, practical guidelines | Success: New contributors can understand test strategy | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 4.2 Add test category enforcement
  - File: `keyrx_ui/vitest.config.base.ts`, `.eslintrc.js`
  - Add ESLint rule: test files must match naming convention
  - Add Vitest config validation for test categories
  - Warn if test count ratio is off (e.g., too many E2E)
  - Purpose: Maintain healthy test balance
  - _Leverage: ESLint custom rules, Vitest reporters_
  - _Requirements: Test balance automatically checked_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Linting Rules Developer | Task: Add ESLint rule to enforce test naming: *.test.tsx for unit, *.integration.test.tsx for integration. Add custom Vitest reporter to count tests per category and warn if balance > 80/15/5 deviation. | Restrictions: Warning only, don't block CI | Success: Test balance visible in CI output | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

---

## Task 5: Improve Test Coverage

- [ ] 5.1 Fix coverage collection to complete successfully
  - File: `keyrx_ui/vitest.config.base.ts`
  - Ensure coverage runs with passing tests
  - Configure coverage exclusions (test files, mocks, types)
  - Add coverage per-file thresholds for critical paths
  - Purpose: Get accurate coverage metrics
  - _Leverage: keyrx_ui/vitest.config.base.ts coverage section_
  - _Requirements: Coverage collection completes_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Coverage Config Engineer | Task: Update coverage config: Exclude test/*, mocks/*, types/*, *.d.ts. Add per-file overrides for critical paths (hooks/, api/) with 90% threshold. Ensure coverage runs after test fixes complete. | Restrictions: Don't lower global 80% threshold | Success: npm run test:coverage completes with report | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 5.2 Add coverage for untested critical paths
  - Files: Identify via coverage report
  - Priority: hooks/ (useUnifiedApi, useWasm)
  - Priority: api/ (rpc.ts, client.ts)
  - Priority: utils/ (rhaiParser, rhaiCodeGen)
  - Add tests to reach 80% on each critical file
  - Purpose: Ensure critical code has test coverage
  - _Leverage: Coverage report, existing test patterns_
  - _Requirements: Critical paths at ≥80% coverage_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Coverage Engineer | Task: After coverage report: 1) Identify files < 80%, 2) Prioritize hooks/ and api/, 3) Write tests for uncovered branches, 4) Focus on error paths and edge cases. Target ≥80% per critical file. | Restrictions: Quality tests, not coverage-padding | Success: All hooks/ and api/ files ≥80% coverage | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 5.3 Add coverage trend tracking
  - File: `scripts/coverage-trend.sh` (create), CI workflow
  - Store coverage percentages per run
  - Compare with previous run, fail if regression > 2%
  - Generate coverage badge for README
  - Purpose: Prevent coverage regression
  - _Leverage: Vitest JSON coverage output, CI artifacts_
  - _Requirements: Coverage trend visible and protected_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: CI Metrics Developer | Task: Create coverage-trend.sh: Extract coverage from JSON, compare with stored baseline, fail if lines coverage drops > 2%. Add to CI as quality gate. Generate shields.io badge URL. | Restrictions: Store baseline in repo, not external service | Success: Coverage regression detected in CI | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

---

## Task 6: Backend Test Improvements

- [ ] 6.1 Add Rust test coverage with tarpaulin
  - File: `scripts/test.sh`, `.github/workflows/ci.yml`
  - Install cargo-tarpaulin in CI
  - Add `--coverage` flag to test.sh
  - Set 80% threshold for keyrx_core, keyrx_compiler
  - Generate HTML and lcov reports
  - Purpose: Backend coverage visibility
  - _Leverage: cargo-tarpaulin documentation_
  - _Requirements: Backend coverage measured and reported_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Rust CI Engineer | Task: Add tarpaulin to CI: Install via cargo install. Run with --out Html,Lcov. Add coverage threshold check (80% keyrx_core). Upload coverage artifact. Add --coverage flag to test.sh. | Restrictions: Don't block CI on daemon coverage (platform-specific) | Success: Backend coverage visible in CI artifacts | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 6.2 Optimize Rust test execution time
  - File: `Cargo.toml` workspace, test configuration
  - Enable parallel test execution
  - Add `--test-threads` optimization
  - Cache compiled test binaries in CI
  - Purpose: Faster backend test feedback
  - _Leverage: Cargo test configuration_
  - _Requirements: Backend tests run faster_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Rust Build Optimizer | Task: Optimize cargo test: Set RUST_TEST_THREADS based on CI runners. Add nextest for faster execution if beneficial. Cache target/debug/deps in CI. Measure before/after times. | Restrictions: Don't break test isolation | Success: Backend tests 20%+ faster | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

---

## Task 7: E2E Test Improvements

- [ ] 7.1 Add E2E test retry and stability improvements
  - File: `keyrx_ui/playwright.e2e.config.ts`
  - Add retry: 2 for flaky network tests
  - Add explicit waits for daemon readiness
  - Add test isolation (fresh browser context per test)
  - Add screenshot on every failure
  - Purpose: More reliable E2E tests
  - _Leverage: keyrx_ui/playwright.e2e.config.ts_
  - _Requirements: E2E tests are stable and debuggable_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Playwright Expert | Task: Update playwright.e2e.config: Add retries: 2, fullyParallel: false, screenshot: 'only-on-failure', video: 'retain-on-failure'. Add beforeAll check for daemon health. Add trace: 'retain-on-failure'. | Restrictions: Keep sequential execution for state-dependent tests | Success: E2E tests pass reliably, failures are debuggable | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 7.2 Add visual regression testing
  - File: `keyrx_ui/e2e/`, Playwright config
  - Add screenshot comparison for key pages
  - Configure snapshot update workflow
  - Add visual diff in CI artifacts
  - Purpose: Catch unintended UI changes
  - _Leverage: Playwright toHaveScreenshot()_
  - _Requirements: Visual changes require explicit approval_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Visual Testing Engineer | Task: Add visual regression: Create e2e/visual.spec.ts with screenshot tests for Dashboard, Config, Profiles pages. Use toHaveScreenshot() with 0.1% threshold. Add --update-snapshots script. Store snapshots in e2e/screenshots/. | Restrictions: Only key pages, not every state | Success: UI changes caught by visual diff | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

---

## Task 8: CI/CD Test Pipeline Optimization

- [ ] 8.1 Parallelize CI test jobs
  - File: `.github/workflows/ci.yml`
  - Split frontend tests into shards (3 shards)
  - Run unit/integration/E2E in parallel where possible
  - Add job dependency optimization
  - Purpose: Reduce total CI time from 45min to 30min
  - _Leverage: .github/workflows/ci.yml_
  - _Requirements: CI completes in ≤30 minutes_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: GitHub Actions Optimizer | Task: Optimize ci.yml: Add matrix strategy for frontend tests (3 shards). Run accessibility tests in parallel with unit tests. Add concurrency limits. Merge coverage from shards. Target 30min total. | Restrictions: Keep quality gates, don't skip tests | Success: CI completes in ≤30 minutes | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 8.2 Add test result caching
  - File: `.github/workflows/ci.yml`
  - Cache Vitest results for unchanged files
  - Cache Playwright browser binaries
  - Cache Rust test compilation
  - Purpose: Faster CI on incremental changes
  - _Leverage: GitHub Actions cache_
  - _Requirements: Incremental test runs are faster_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: CI Cache Engineer | Task: Add caching: Cache ~/.cache/ms-playwright, node_modules/.vitest, target/debug/deps. Use hash of lock files as cache key. Add cache-hit detection to skip redundant work. | Restrictions: Invalidate cache on config changes | Success: Repeat CI runs 50%+ faster | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

---

## Task 9: Test Quality Metrics Dashboard

- [ ] 9.1 Add test metrics collection
  - File: `scripts/test-metrics.sh` (create)
  - Collect: pass rate, duration, coverage, flaky test count
  - Store in JSON format for trending
  - Add to CI as artifact
  - Purpose: Track test health over time
  - _Leverage: Vitest JSON reporter, CI artifacts_
  - _Requirements: Test metrics collected per CI run_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Metrics Developer | Task: Create test-metrics.sh: Parse Vitest JSON output, extract passCount, failCount, duration, coverage. Generate metrics.json with timestamp. Add to CI artifacts. Include flaky test detection (tests that pass on retry). | Restrictions: Simple JSON format, no external services | Success: Metrics JSON available in CI artifacts | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

- [ ] 9.2 Add flaky test detection and quarantine
  - File: `keyrx_ui/tests/quarantine.json` (create), test config
  - Track tests that fail intermittently
  - Add quarantine list for known flaky tests
  - Run quarantined tests separately, don't block CI
  - Alert when quarantine grows
  - Purpose: Separate flaky tests from real failures
  - _Leverage: Vitest test retry data_
  - _Requirements: Flaky tests identified and managed_
  - _Prompt: Implement the task for spec test-overhaul, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Test Reliability Engineer | Task: Create quarantine system: quarantine.json lists flaky test names. Vitest config excludes quarantined tests from main run. Add separate "test:quarantine" script. Add script to detect new flaky tests (passed on retry). | Restrictions: Quarantine should shrink over time, not grow | Success: Flaky tests don't block CI, are tracked separately | After completion: Mark task [-] as in-progress in tasks.md before starting, use log-implementation tool to record artifacts, then mark [x] complete_

---

## Summary

| Task | Description | Impact |
|------|-------------|--------|
| 1.1-1.3 | Fix WebSocket mock infrastructure | Unblocks 72 tests |
| 2.1-2.2 | Fix async/timing issues | Fixes 3 more failures |
| 3.1-3.3 | Improve test productivity | 30%+ faster dev feedback |
| 4.1-4.2 | Establish test balance strategy | Sustainable test growth |
| 5.1-5.3 | Improve coverage | ≥80% coverage achieved |
| 6.1-6.2 | Backend test improvements | Backend coverage + speed |
| 7.1-7.2 | E2E test improvements | Stable E2E + visual regression |
| 8.1-8.2 | CI/CD optimization | CI ≤30min |
| 9.1-9.2 | Test quality metrics | Visibility + flaky management |

**Total: 18 subtasks**

## Expected Outcomes
- Frontend tests: 75.9% → ≥95% pass rate
- Coverage: Blocked → ≥80%
- CI time: 45min → ≤30min
- Dev feedback: 5s timeout → ≤3s with focused runs
- Flaky tests: Unmanaged → Quarantined and tracked
